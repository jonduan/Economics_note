{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T04:57:24.502368Z",
     "start_time": "2017-11-05T04:57:22.629174Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Gradient descent\n",
    "==================\n",
    "\n",
    "An example demoing gradient descent by creating figures that trace the\n",
    "evolution of the optimizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T04:57:27.918643Z",
     "start_time": "2017-11-05T04:57:26.438267Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cost_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6fe3ff47cc8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'helper'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcost_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmk_quad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmk_gauss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrosenbrock\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mrosenbrock_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrosenbrock_hessian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLoggingFunction\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mCountingFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'cost_functions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy import optimize\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('helper'))\n",
    "from cost_functions import mk_quad, mk_gauss, rosenbrock,\\\n",
    "    rosenbrock_prime, rosenbrock_hessian, LoggingFunction,\\\n",
    "    CountingFunction\n",
    "\n",
    "x_min, x_max = -1, 2\n",
    "y_min, y_max = 2.25/3*x_min - .2, 2.25/3*x_max - .2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A formatter to print values on contours\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T05:14:58.971802Z",
     "start_time": "2017-11-05T05:14:58.960202Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def super_fmt(value):\n",
    "    if value > 1:\n",
    "        if np.abs(int(value) - value) < .1:\n",
    "            out = '$10^{%.1i}$' % value\n",
    "        else:\n",
    "            out = '$10^{%.1f}$' % value\n",
    "    else:\n",
    "        value = np.exp(value - .01)\n",
    "        if value > .1:\n",
    "            out = '%1.1f' % value\n",
    "        elif value > .01:\n",
    "            out = '%.2f' % value\n",
    "        else:\n",
    "            out = '%.2e' % value\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gradient descent algorithm\n",
    "do not use: its a toy, use scipy's optimize.fmin_cg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T05:15:00.173050Z",
     "start_time": "2017-11-05T05:14:59.916354Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x0, f, f_prime, hessian=None, adaptative=False):\n",
    "    x_i, y_i = x0\n",
    "    all_x_i = list()\n",
    "    all_y_i = list()\n",
    "    all_f_i = list()\n",
    "\n",
    "    for i in range(1, 100):\n",
    "        all_x_i.append(x_i)\n",
    "        all_y_i.append(y_i)\n",
    "        all_f_i.append(f([x_i, y_i]))\n",
    "        dx_i, dy_i = f_prime(np.asarray([x_i, y_i]))\n",
    "        if adaptative:\n",
    "            # Compute a step size using a line_search to satisfy the Wolf\n",
    "            # conditions\n",
    "            step = optimize.line_search(f, f_prime,\n",
    "                                np.r_[x_i, y_i], -np.r_[dx_i, dy_i],\n",
    "                                np.r_[dx_i, dy_i], c2=.05)\n",
    "            step = step[0]\n",
    "            if step is None:\n",
    "                step = 0\n",
    "        else:\n",
    "            step = 1\n",
    "        x_i += - step*dx_i\n",
    "        y_i += - step*dy_i\n",
    "        if np.abs(all_f_i[-1]) < 1e-16:\n",
    "            break\n",
    "    return all_x_i, all_y_i, all_f_i\n",
    "\n",
    "\n",
    "def gradient_descent_adaptative(x0, f, f_prime, hessian=None):\n",
    "    return gradient_descent(x0, f, f_prime, adaptative=True)\n",
    "\n",
    "\n",
    "def conjugate_gradient(x0, f, f_prime, hessian=None):\n",
    "    all_x_i = [x0[0]]\n",
    "    all_y_i = [x0[1]]\n",
    "    all_f_i = [f(x0)]\n",
    "    def store(X):\n",
    "        x, y = X\n",
    "        all_x_i.append(x)\n",
    "        all_y_i.append(y)\n",
    "        all_f_i.append(f(X))\n",
    "    optimize.minimize(f, x0, jac=f_prime, method=\"CG\", callback=store, options={\"gtol\": 1e-12})\n",
    "    return all_x_i, all_y_i, all_f_i\n",
    "\n",
    "\n",
    "def newton_cg(x0, f, f_prime, hessian):\n",
    "    all_x_i = [x0[0]]\n",
    "    all_y_i = [x0[1]]\n",
    "    all_f_i = [f(x0)]\n",
    "    def store(X):\n",
    "        x, y = X\n",
    "        all_x_i.append(x)\n",
    "        all_y_i.append(y)\n",
    "        all_f_i.append(f(X))\n",
    "    optimize.minimize(f, x0, method=\"Newton-CG\", jac=f_prime, hess=hessian, callback=store, options={\"xtol\": 1e-12})\n",
    "    return all_x_i, all_y_i, all_f_i\n",
    "\n",
    "\n",
    "def bfgs(x0, f, f_prime, hessian=None):\n",
    "    all_x_i = [x0[0]]\n",
    "    all_y_i = [x0[1]]\n",
    "    all_f_i = [f(x0)]\n",
    "    def store(X):\n",
    "        x, y = X\n",
    "        all_x_i.append(x)\n",
    "        all_y_i.append(y)\n",
    "        all_f_i.append(f(X))\n",
    "    optimize.minimize(f, x0, method=\"BFGS\", jac=f_prime, callback=store, options={\"gtol\": 1e-12})\n",
    "    return all_x_i, all_y_i, all_f_i\n",
    "\n",
    "\n",
    "def powell(x0, f, f_prime, hessian=None):\n",
    "    all_x_i = [x0[0]]\n",
    "    all_y_i = [x0[1]]\n",
    "    all_f_i = [f(x0)]\n",
    "    def store(X):\n",
    "        x, y = X\n",
    "        all_x_i.append(x)\n",
    "        all_y_i.append(y)\n",
    "        all_f_i.append(f(X))\n",
    "    optimize.minimize(f, x0, method=\"Powell\", callback=store, options={\"ftol\": 1e-12})\n",
    "    return all_x_i, all_y_i, all_f_i\n",
    "\n",
    "\n",
    "def nelder_mead(x0, f, f_prime, hessian=None):\n",
    "    all_x_i = [x0[0]]\n",
    "    all_y_i = [x0[1]]\n",
    "    all_f_i = [f(x0)]\n",
    "    def store(X):\n",
    "        x, y = X\n",
    "        all_x_i.append(x)\n",
    "        all_y_i.append(y)\n",
    "        all_f_i.append(f(X))\n",
    "    optimize.minimize(f, x0, method=\"Nelder-Mead\", callback=store, options={\"ftol\": 1e-12})\n",
    "    return all_x_i, all_y_i, all_f_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run different optimizers on these problems\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T05:15:01.191584Z",
     "start_time": "2017-11-05T05:15:00.997581Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mk_quad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0b17cfb0e595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m for index, ((f, f_prime, hessian), optimizer) in enumerate((\n\u001b[1;32m----> 4\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mmk_quad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mmk_quad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient_descent_adaptative\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mmk_quad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.02\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mk_quad' is not defined"
     ]
    }
   ],
   "source": [
    "levels = dict()\n",
    "\n",
    "for index, ((f, f_prime, hessian), optimizer) in enumerate((\n",
    "                (mk_quad(.7), gradient_descent),\n",
    "                (mk_quad(.7), gradient_descent_adaptative),\n",
    "                (mk_quad(.02), gradient_descent),\n",
    "                (mk_quad(.02), gradient_descent_adaptative),\n",
    "                (mk_gauss(.02), gradient_descent_adaptative),\n",
    "                ((rosenbrock, rosenbrock_prime, rosenbrock_hessian),\n",
    "                                    gradient_descent_adaptative),\n",
    "                (mk_gauss(.02), conjugate_gradient),\n",
    "                ((rosenbrock, rosenbrock_prime, rosenbrock_hessian),\n",
    "                                    conjugate_gradient),\n",
    "                (mk_quad(.02), newton_cg),\n",
    "                (mk_gauss(.02), newton_cg),\n",
    "                ((rosenbrock, rosenbrock_prime, rosenbrock_hessian),\n",
    "                                    newton_cg),\n",
    "                (mk_quad(.02), bfgs),\n",
    "                (mk_gauss(.02), bfgs),\n",
    "                ((rosenbrock, rosenbrock_prime, rosenbrock_hessian),\n",
    "                            bfgs),\n",
    "                (mk_quad(.02), powell),\n",
    "                (mk_gauss(.02), powell),\n",
    "                ((rosenbrock, rosenbrock_prime, rosenbrock_hessian),\n",
    "                            powell),\n",
    "                (mk_gauss(.02), nelder_mead),\n",
    "                ((rosenbrock, rosenbrock_prime, rosenbrock_hessian),\n",
    "                            nelder_mead),\n",
    "            )):\n",
    "\n",
    "    # Compute a gradient-descent\n",
    "    x_i, y_i = 1.6, 1.1\n",
    "    counting_f_prime = CountingFunction(f_prime)\n",
    "    counting_hessian = CountingFunction(hessian)\n",
    "    logging_f = LoggingFunction(f, counter=counting_f_prime.counter)\n",
    "    all_x_i, all_y_i, all_f_i = optimizer(np.array([x_i, y_i]),\n",
    "                                          logging_f, counting_f_prime,\n",
    "                                          hessian=counting_hessian)\n",
    "\n",
    "    # Plot the contour plot\n",
    "    if not max(all_y_i) < y_max:\n",
    "        x_min *= 1.2\n",
    "        x_max *= 1.2\n",
    "        y_min *= 1.2\n",
    "        y_max *= 1.2\n",
    "    x, y = np.mgrid[x_min:x_max:100j, y_min:y_max:100j]\n",
    "    x = x.T\n",
    "    y = y.T\n",
    "\n",
    "    pl.figure(index, figsize=(3, 2.5))\n",
    "    pl.clf()\n",
    "    pl.axes([0, 0, 1, 1])\n",
    "\n",
    "    X = np.concatenate((x[np.newaxis, ...], y[np.newaxis, ...]), axis=0)\n",
    "    z = np.apply_along_axis(f, 0, X)\n",
    "    log_z = np.log(z + .01)\n",
    "    pl.imshow(log_z,\n",
    "            extent=[x_min, x_max, y_min, y_max],\n",
    "            cmap=pl.cm.gray_r, origin='lower',\n",
    "            vmax=log_z.min() + 1.5*log_z.ptp())\n",
    "    contours = pl.contour(log_z,\n",
    "                        levels=levels.get(f, None),\n",
    "                        extent=[x_min, x_max, y_min, y_max],\n",
    "                        cmap=pl.cm.gnuplot, origin='lower')\n",
    "    levels[f] = contours.levels\n",
    "    pl.clabel(contours, inline=1,\n",
    "                fmt=super_fmt, fontsize=14)\n",
    "\n",
    "    pl.plot(all_x_i, all_y_i, 'b-', linewidth=2)\n",
    "    pl.plot(all_x_i, all_y_i, 'k+')\n",
    "\n",
    "    pl.plot(logging_f.all_x_i, logging_f.all_y_i, 'k.', markersize=2)\n",
    "\n",
    "    pl.plot([0], [0], 'rx', markersize=12)\n",
    "\n",
    "\n",
    "    pl.xticks(())\n",
    "    pl.yticks(())\n",
    "    pl.xlim(x_min, x_max)\n",
    "    pl.ylim(y_min, y_max)\n",
    "    pl.draw()\n",
    "\n",
    "    pl.figure(index + 100, figsize=(4, 3))\n",
    "    pl.clf()\n",
    "    pl.semilogy(np.maximum(np.abs(all_f_i), 1e-30), linewidth=2,\n",
    "                label='# iterations')\n",
    "    pl.ylabel('Error on f(x)')\n",
    "    pl.semilogy(logging_f.counts,\n",
    "                np.maximum(np.abs(logging_f.all_f_i), 1e-30),\n",
    "                linewidth=2, color='g', label='# function calls')\n",
    "    pl.legend(loc='upper right', frameon=True, prop=dict(size=11),\n",
    "              borderaxespad=0, handlelength=1.5, handletextpad=.5)\n",
    "    pl.tight_layout()\n",
    "    pl.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
